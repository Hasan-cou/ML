{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976f458c",
   "metadata": {},
   "source": [
    "# Charts for paper - Random Forest Classifier\n",
    "\n",
    "## Purpose and Context\n",
    "\n",
    "This notebook is for creating the classifier charts and data utilized in the final paper\n",
    "\n",
    "## Setup\n",
    "\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6588cadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import tqdm.notebook\n",
    "tqdm.notebook.tqdm_notebook.pandas()\n",
    "\n",
    "import utils\n",
    "import labels\n",
    "import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3557d",
   "metadata": {},
   "source": [
    "### Set Styles and colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec76953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style = \"whitegrid\", font_scale = 1.1, font = 'Calibri')\n",
    "sns.despine(left = True)\n",
    "\n",
    "colors = ['#e66101', '#fdb863', '#b2abd2', '#5e3c99']\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "figureSize = (4, 3)\n",
    "padInches = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62251f81",
   "metadata": {},
   "source": [
    "## Training results\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea795d5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output\\\\dataset-development.gzip.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m development \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadDataFromOutput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset-development\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m validation \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mLoadDataFromOutput(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset-validation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevelopement Dataset Count: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(development)))\n",
      "File \u001b[1;32m~\\PycharmProjects\\PredictEpsilon-Publish-main\\code\\utils.py:148\u001b[0m, in \u001b[0;36mLoadDataFromOutput\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadDataFromOutput\u001b[39m(name):\n\u001b[1;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputDirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.gzip.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:501\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03mDataFrame\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    502\u001b[0m     path,\n\u001b[0;32m    503\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    504\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    505\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    507\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:242\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    240\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilesystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    250\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    251\u001b[0m     )\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m     92\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:866\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output\\\\dataset-development.gzip.parquet'"
     ]
    }
   ],
   "source": [
    "development = utils.LoadDataFromOutput('dataset-development')\n",
    "validation = utils.LoadDataFromOutput('dataset-validation')\n",
    "print('Developement Dataset Count: ' + str(len(development)))\n",
    "print('Validate Dataset Count: ' + str(len(validation)))\n",
    "\n",
    "data = pd.concat([development, validation]).reset_index(drop = True)\n",
    "print('Total Count: ' + str(len(data)))\n",
    "print('Number of Training Features: ' + str(len(development.columns)))\n",
    "development.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d777b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "models = pd.read_parquet('trainedModels-RandomForestClassifier.gzip.parquet')\n",
    "models['Model Params'] = models['Model'].apply(ast.literal_eval)\n",
    "models.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620f74a",
   "metadata": {},
   "source": [
    "### Classifier Results\n",
    "\n",
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "def ComputeAllowsLowAccuracy(threshold, data):\n",
    "    _, y = train.GetXandY(data)\n",
    "    y = train.ComputeLabel(y, threshold)\n",
    "    \n",
    "    y_pred = data['Epsilon'].apply(lambda x: 'low ε')\n",
    "\n",
    "    return skm.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe82883",
   "metadata": {},
   "source": [
    "#### Best Model with the least amount of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cca151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = models.copy()\n",
    "temp = temp.join(temp['Model Params'].apply(lambda x: pd.Series(x, dtype = 'object')))\n",
    "temp['Accuracy'] = temp['Accuracy'].apply(lambda x: np.round(x, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb7818",
   "metadata": {},
   "source": [
    "Computing the amount of information encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25339a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Total Information Used'] = temp.apply(lambda row: train.ComputeTotalInfomationUsed(row, len(development.columns)), axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73538e4e",
   "metadata": {},
   "source": [
    " Selecting the models with the highest accuracy and the lowest information used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccuracy = temp.groupby(['Threshold']).max('Accuracy')['Accuracy'].reset_index()\n",
    "maxAccuracy\n",
    "totalInformationUsed = temp.merge(maxAccuracy, on = ['Threshold', 'Accuracy']).groupby(['Threshold']).min('Total Information Used')[['Accuracy', 'Total Information Used']].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ef734",
   "metadata": {},
   "source": [
    "Selecting the models with the highest precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostAccurateAndPreciseWithTheLeastAmountOfInformation = temp.merge(totalInformationUsed, on = ['Threshold', 'Accuracy', 'Total Information Used']).groupby(['Threshold']).max('Precision (High ε)').reset_index()\n",
    "bestModels = temp.merge(mostAccurateAndPreciseWithTheLeastAmountOfInformation[['Threshold', 'Accuracy', 'Total Information Used', 'Precision (High ε)']], on = ['Threshold', 'Accuracy', 'Total Information Used', 'Precision (High ε)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d9776",
   "metadata": {},
   "source": [
    "If there are still multiple models, then take the first one since they are identical from our point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365150f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModels = bestModels.groupby(['Threshold']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a577bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestModels['Model'] = bestModels.progress_apply(lambda x: train.TrainRandomForestClassifier(x['Model Params'], x['Threshold'], development), axis = 'columns')\n",
    "bestModels['Random Forest Classifier(Development)'] = bestModels.apply(lambda x: train.ComputeClassifierAccuracy(x['Model'], x['Threshold'], development), axis = 'columns')\n",
    "bestModels['Random Forest Classifier(Validation)'] = bestModels.apply(lambda x: train.ComputeClassifierAccuracy(x['Model'], x['Threshold'], validation), axis = 'columns')\n",
    "bestModels['Always Low ε(Development)'] = bestModels.apply(lambda x: ComputeAllowsLowAccuracy(x['Threshold'], development), axis = 'columns')\n",
    "bestModels['Always Low ε(Validation)'] = bestModels.apply(lambda x: ComputeAllowsLowAccuracy(x['Threshold'], validation), axis = 'columns')\n",
    "bestModels.head(1)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "classifierModelUsed = bestModels.iloc[1]\n",
    "\n",
    "low = data[data['Epsilon'] < classifierModelUsed['Threshold']].reset_index(drop = True).copy()\n",
    "high = data[data['Epsilon'] >= classifierModelUsed['Threshold']].reset_index(drop = True).copy()\n",
    "total = len(low) + len(high)\n",
    "\n",
    "percentageLowRuns = []\n",
    "for lowPercent in range(50, 100, 2):\n",
    "    lowPercent = lowPercent / 100\n",
    "    numberOfHighsNeeded = int(len(low) / lowPercent - len(low))\n",
    "    newHighs = resample(high, n_samples = numberOfHighsNeeded, random_state = 82219)\n",
    "    lowEpsilonDevelopment, lowEpsilonValidation = train.SplitData(pd.concat([low, newHighs], ignore_index = True))\n",
    "\n",
    "    percentageLowRuns.append([lowPercent, lowEpsilonDevelopment, lowEpsilonValidation])\n",
    "    \n",
    "percentageLowRuns = pd.DataFrame(percentageLowRuns, columns = ['Percentage Low ε', 'Development', 'Validation'])\n",
    "\n",
    "percentageLowRuns['Model'] = percentageLowRuns.progress_apply(lambda x: train.TrainRandomForestClassifier(classifierModelUsed['Model Params'], classifierModelUsed['Threshold'], x['Development']), axis = 'columns')\n",
    "percentageLowRuns['Random Forest Classifier(Development)'] = percentageLowRuns.apply(lambda x: train.ComputeClassifierAccuracy(x['Model'], classifierModelUsed['Threshold'], x['Development']), axis = 'columns')\n",
    "percentageLowRuns['Random Forest Classifier(Validation)'] = percentageLowRuns.apply(lambda x: train.ComputeClassifierAccuracy(x['Model'], classifierModelUsed['Threshold'], x['Validation']), axis = 'columns')\n",
    "percentageLowRuns['Always Low ε(Development)'] = percentageLowRuns.apply(lambda x: ComputeAllowsLowAccuracy(classifierModelUsed['Threshold'], x['Development']), axis = 'columns')\n",
    "percentageLowRuns['Always Low ε(Validation)'] = percentageLowRuns.apply(lambda x: ComputeAllowsLowAccuracy(classifierModelUsed['Threshold'], x['Validation']), axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols = 2, figsize = (11, 4), constrained_layout = True)\n",
    "\n",
    "graphData = bestModels[['Threshold', 'Random Forest Classifier(Development)', 'Random Forest Classifier(Validation)', 'Always Low ε(Development)', 'Always Low ε(Validation)']]\n",
    "graphData = graphData.melt(id_vars = ['Threshold'])\n",
    "graphData['Threshold'] = graphData['Threshold'] / 1000\n",
    "\n",
    "g = sns.lineplot(data = graphData, x = 'Threshold', y = 'value', hue = 'variable', ax = axes[0])\n",
    "g.set(ylim = (.9, 1), ylabel = 'Accuracy', xlabel = labels.EpsilonFull);\n",
    "g.legend_.set_title('Model (Dataset)')\n",
    "\n",
    "graphData = percentageLowRuns.drop(['Development', 'Validation', 'Model'], axis = 'columns').melt('Percentage Low ε')\n",
    "\n",
    "g = sns.lineplot(data = graphData, x = 'Percentage Low ε', y = 'value', hue = 'variable', ax = axes[1])\n",
    "g.set(ylabel = 'Accuracy', xlabel = 'Percentage Low ε in Dataset');\n",
    "g.legend_.set_title('Model(Dataset)')\n",
    "\n",
    "fig.savefig('../output/chart-overall-RandomForestClassifier.png', bbox_inches = 'tight', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classifier model used in experiments:')\n",
    "print('Threshold of ' + str(classifierModelUsed['Threshold']))\n",
    "display(classifierModelUsed['Model Params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c2c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
